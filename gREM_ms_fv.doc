<h2 id="running-title-a-generalised-random-encounter-model-for-animals"> Running title: A generalised random encounter model for animals</h2>
<h2 id="word-count"> Word count:</h2>
<p>9837</p>
<h2 id="authors"> Authors:<br /></h2>
<p>Tim C.D. Lucas<sup>1,2,3</sup><span class="math"> † </span>, Elizabeth A. Moorcroft<sup>1,4,5</sup><span class="math"> † </span>, Robin Freeman<sup>5</sup>, Marcus J. Rowcliffe<sup>5</sup>, Kate E. Jones<sup>2,5</sup></p>
<h2 id="addresses"> Addresses:<br /></h2>
<p>1 CoMPLEX, University College London, Physics Building, Gower Street, London, WC1E 6BT, UK<br />2 Centre for Biodiversity and Environment Research, Department of Genetics, Evolution and Environment, University College London, Gower Street, London, WC1E 6BT, UK<br />3 Department of Statistical Science, University College London, Gower Street, London, WC1E 6BT, UK<br />4 Department of Computer Science, University College London, Gower Street, London, WC1E 6BT, UK<br />5 Institute of Zoology, Zoological Society of London, Regents Park, London, NW1 4RY, UK<br /><span class="math"> † </span> First authorship shared.</p>
<h2 id="corresponding-authors"> Corresponding authors:<br /></h2>
<p>Kate E. Jones,<br />Centre for Biodiversity and Environment Research,<br />Department of Genetics, Evolution and Environment,<br />University College London,<br />Gower Street,<br />London,<br />WC1E 6BT,<br />UK<br />kate.e.jones@ucl.ac.uk<br /></p>
<p>Marcus J. Rowcliffe,<br />Institute of Zoology,<br />Zoological Society of London,<br />Regents Park,<br />London,<br />NW1 4RY,<br />UK<br />marcus.rowcliffe@ioz.ac.uk</p>
<h1 id="abstract">Abstract</h1>
<h2 id="section">1:</h2>
<p>Wildlife monitoring technology is advancing rapidly and the use of remote sensors such as camera traps and acoustic detectors is becoming common in both the terrestrial and marine environments. Current methods to estimate abundance or density require individual recognition of animals or knowing the distance of the animal from the sensor, which is often difficult. A method without these requirements, the random encounter model (REM), has been successfully applied to estimate animal densities from count data generated from camera traps. However, count data from acoustic detectors do not fit the assumptions of the REM due to the directionality of animal signals.</p>
<h2 id="section-1">2:</h2>
<p>We developed a generalised REM (gREM), to estimate absolute animal density from count data from both camera traps and acoustic detectors. We derived the gREM for different combinations of sensor detection widths and animal signal widths (a measure of directionality). We tested the accuracy and precision of this model using simulations of different combinations of sensor detection widths and animal signal widths, number of captures, and models of animal movement.</p>
<h2 id="section-2">3:</h2>
<p>We find that the gREM produces accurate estimates of absolute animal density for all combinations of sensor detection widths and animal signal widths. However, larger sensor detection and animal signal widths were found to be more precise. While the model is accurate for all capture efforts tested, the precision of the estimate increases with the number of captures. We found no effect of different animal movement models on the accuracy and precision of the gREM.</p>
<h2 id="section-3">4:</h2>
<p>We conclude that the gREM provides an effective method to estimate absolute animal densities from remote sensor count data over a range of sensor and animal signal widths. The gREM is applicable for count data obtained in both marine and terrestrial environments, visually or acoustically (e.g., big cats, sharks, birds, bats and cetaceans). As sensors such as camera traps and acoustic detectors become more ubiquitous, the gREM will be increasingly useful for monitoring unmarked animal populations across broad spatial, temporal and taxonomic scales.</p>
<h2 id="keywords">Keywords</h2>
<p>Acoustic detection, camera traps, marine, population monitoring, simulations, terrestrial</p>
<h1 id="introduction">Introduction</h1>
<p>Animal population density is one of the fundamental measures in ecology and conservation. The density of a population has important implications for a range of issues such as sensitivity to stochastic fluctuations <span class="citation"></span> and risk of extinction <span class="citation"></span>. Monitoring animal population changes in response to anthropogenic pressure is becoming increasingly important as humans rapidly modify habitats and change climates <span class="citation"></span>. Sensor technology, such as camera traps <span class="citation"></span> and acoustic detectors <span class="citation"></span> are becoming increasingly used to monitor changes in animal populations <span class="citation"></span>, as they are efficient, relativity cheap and non-invasive <span class="citation"></span>, allowing for surveys over large areas and long periods. However, converting sampled count data into estimates of density is problematic as detectability of animals needs to be accounted for <span class="citation"></span>.</p>
<p>Existing methods for estimating animal density often require additional information that may not be available. For example, capture-mark-recapture methods <span class="citation"></span> require recognition of individuals, and distance methods <span class="citation"></span> require an estimation of how far away individuals are from the sensor <span class="citation"></span>. The development of the random encounter model (REM) (a modification of a gas model) has enabled animal densities to be estimated from unmarked individuals of a known speed, and with known sensor detection parameters <span class="citation"></span>. The REM method has been successfully applied to estimate animal densities from camera trap surveys <span class="citation"></span>. However, extending the REM method to other types of sensors (e.g., acoustic detectors) is more problematic, because the original derivation assumes a relatively narrow sensor width (up to <span class="math"><em>π</em> / 2</span> radians) and that the animal is equally detectable irrespective of its heading <span class="citation"></span>.</p>
<p>Whilst these restrictions are not problematic for most camera trap makes (e.g., Reconyx, Cuddeback), the REM cannot be used to estimate densities from camera traps with a wider sensor width (e.g. canopy monitoring with fish eye lenses <span class="citation"></span>. Additionally, the REM method is not useful in estimating densities from acoustic survey data as the acoustic detector angles are often wider than <span class="math"><em>π</em> / 2</span> radians. Acoustic detectors are designed for a range of diverse tasks and environments <span class="citation"></span>, which will naturally lead to a wide range of sensor detection widths and detection distances. In addition to this, calls emitted by many animals are directional <span class="citation"></span> breaking the assumption of the REM method.</p>
<p>There has been a sharp rise in interest around passive acoustic detectors in recent years, with a 10 fold increase in publications in the decade between 2000 and 2010 <span class="citation"></span>. Acoustic monitoring is being developed to study many aspects of ecology, including the interactions of animals and their environments <span class="citation"></span>, the presence and relative abundances of species <span class="citation"></span>, biodiversity of an area <span class="citation"></span>, and monitoring population trends <span class="citation"></span>.</p>
<p>Acoustic data suffers from many of the problems associated with data from camera trap surveys in that individuals are often unmarked so capture-mark-recapture methods cannot be used to estimate densities. In some cases the distance between the animal and the sensor is known, for example when an array of sensors and the position of the animal is estimated by triangulation <span class="citation"></span>. In these situations distance-sampling methods can be applied, a method typically used for marine mammals <span class="citation"></span>. However, in many cases distance estimation is not possible, for example when single sensors are deployed, a situation typical in the majority of terrestrial acoustic surveys <span class="citation"></span>. In these cases, only relative measures of local abundance can be calculated, and not absolute densities. This means that comparison of populations between species and sites is problematic without assuming equal detectability <span class="citation"></span>. Equal detectability is unlikely because of differences in environmental conditions, sensor type, habitat, and species biology.</p>
<p>In this study we create a generalised REM (gREM), as an extension to the camera trap model of <span class="citation"></span>, to estimate absolute density from count data from acoustic detectors, or camera traps, where the sensor width can vary from 0 to <span class="math">2<em>π</em></span> radians, and the signal given from the animal can be directional. We assessed the accuracy and precision of the gREM within a simulated environment, by varying the sensor detection widths, animal signal widths, number of captures and models of animal movement. We use the simulation results to recommend best survey practice for estimating animal densities from remote sensors.</p>
<h1 id="methods">Methods</h1>
<h2 id="analytical-model">Analytical Model</h2>
<p>The REM presented by <span class="citation"></span> adapts the gas model to count data collected from camera trap surveys. The REM is derived assuming a stationary sensor with a detection width less than <span class="math"><em>π</em> / 2</span> radians. However, in order to apply this approach more generally, and in particular to acoustic detectors, we need both to relax the constraint on sensor detection width, and allow for animals with directional signals. Consequently, we derive the gREM for any detection width, <span class="math"><em>θ</em></span>, between 0 and <span class="math">2<em>π</em></span> with a detection distance <span class="math"><em>r</em></span> giving a circular sector within which animals can be captured (the detection zone) (Figure [f:AngleDef]). Additionally, we model the animal as having an associated signal width <span class="math"><em>α</em></span> between 0 and <span class="math">2<em>π</em></span> (Figure [f:AngleDef], see Appendix S1 for a list of symbols). We start deriving the gREM with the simplest situation, the gas model where <span class="math"><em>θ</em> = 2<em>π</em></span> and <span class="math"><em>α</em> = 2<em>π</em></span>.</p>
<p>[t] <embed src="imgs/angleDefinitions.pdf"></p>
<p>Representation of sensor detection width and animal signal width. The filled square and circle represent a sensor and an animal, respectively; <span class="math"><em>θ</em></span>, sensor detection width (radians); <span class="math"><em>r</em></span>, sensor detection distance; dark grey shaded area, sensor detection zone; <span class="math"><em>α</em></span>, animal signal width (radians). Dashed lines around the filled square and circle represents the maximum extent of <span class="math"><em>θ</em></span> and <span class="math"><em>α</em></span>, respectively. [f:AngleDef]</p>
<h3 id="gas-model">Gas Model</h3>
<p>Following <span class="citation"></span>, we derive the gas model where sensors can capture animals in any direction and animal signals are detectable from any direction (<span class="math"><em>θ</em> = 2<em>π</em></span> and <span class="math"><em>α</em> = 2<em>π</em></span>). We assume that animals are in a homogeneous environment, and move in straight lines of random direction with velocity <span class="math"><em>v</em></span>. We allow that our stationary sensor can capture animals at a detection distance <span class="math"><em>r</em></span> and that if an animal moves within this detection zone they are captured with a probability of one, while animals outside the zone are never captured.</p>
<p>In order to derive animal density, we need to consider relative velocity from the reference frame of the animals. Conceptually, this requires us to imagine that all animals are stationary and randomly distributed in space, while the sensor moves with velocity <span class="math"><em>v</em></span>. If we calculate the area covered by the sensor during the survey period, we can estimate the number of animals the sensor should capture. As a circle moving across a plane, the area covered by the sensor per unit time is <span class="math">2<em>r</em><em>v</em></span>. The number of expected captures, <span class="math"><em>z</em></span>, for a survey period of <span class="math"><em>t</em></span>, with an animal density of <span class="math"><em>D</em></span> is <span class="math"><em>z</em> = 2<em>r</em><em>v</em><em>t</em><em>D</em></span>. To estimate the density, we rearrange to get <span class="math"><em>D</em> = <em>z</em> / 2<em>r</em><em>v</em><em>t</em></span>.</p>
<h3 id="grem-derivations-for-different-detection-and-signal-widths">gREM derivations for different detection and signal widths</h3>
<p>Different combinations of <span class="math"><em>θ</em></span> and <span class="math"><em>α</em></span> would be expected to occur (e.g., sensors have different detection widths and animals have different signal widths). For different combinations <span class="math"><em>θ</em></span> and <span class="math"><em>α</em></span>, the area covered per unit time is no longer given by <span class="math">2<em>r</em><em>v</em></span>. Instead of the size of the sensor detection zone having a diameter of <span class="math">2<em>r</em></span>, the size changes with the approach angle between the sensor and the animal. For any given signal width and detector width and depending on the angle that the animal approaches the sensor, the width of the area within which an animal can be detected is called the profile, <span class="math"><em>p</em></span>. The size of the profile (averaged across all approach angles) is defined as the average profile <span class="math"><em>p̄</em></span>. However, different combinations of <span class="math"><em>θ</em></span> and <span class="math"><em>α</em></span> need different equations to calculate <span class="math"><em>p̄</em></span>.</p>
<p><embed src="imgs/equalRegions.pdf"> Locations where derivation of the average profile <span class="math"><em>p̄</em></span> is the same for different combinations of sensor detection and animal signal widths. Symbols within each polygon refer to each gREM submodel named after their compass point, except for Gas and REM which highlight the position of these previously derived models within the gREM. Symbols on the edge of the plot are for submodels where <span class="math"><em>α</em>, <em>θ</em> = 2<em>π</em></span> [f:equalRegions]</p>
<p>We have identified the parameter space for the combinations of <span class="math"><em>θ</em></span> and <span class="math"><em>α</em></span> for which the derivation of the equations are the same (defined as sub-models in the gREM) (Figure [f:equalRegions]). For example, the gas model becomes the simplest gREM sub-model (upper right in Figure [f:equalRegions]) and the REM from <span class="citation"></span> is another gREM sub-model where <span class="math"><em>θ</em> &lt; <em>π</em> / 2</span> and <span class="math"><em>α</em> = 2<em>π</em></span>. We derive one gREM sub-model SE2 as an example below, where <span class="math">2<em>π</em> − <em>α</em> / 2 &lt; <em>θ</em> &lt; 2<em>π</em>,  0 &lt; <em>α</em> &lt; <em>π</em></span> (see Appendix S2 for derivations of all gREM sub-models).</p>
<h3 id="example-derivation-of-se2">Example derivation of SE2</h3>
<p>In order to calculate <span class="math"><em>p̄</em></span>, we have to integrate over the focal angle, <span class="math"><em>x</em><sub>1</sub></span> (Figure [f:x1AndInt]a). This is the angle taken from the centre line of the sensor. Other focal angles are possible (<span class="math"><em>x</em><sub>2</sub></span>, <span class="math"><em>x</em><sub>3</sub></span>, <span class="math"><em>x</em><sub>4</sub></span>) and are used in other gREM sub-models (see Appendix S2). As the size of the profile depends on the approach angle, we present the derivation across all approach angles. When the sensor is directly approaching the animal <span class="math"><em>x</em><sub>1</sub> = <em>π</em> / 2</span>.</p>
<p>Starting from <span class="math"><em>x</em><sub>1</sub> = <em>π</em> / 2</span> until <span class="math"><em>θ</em> / 2 + <em>π</em> / 2 − <em>α</em> / 2</span>, the size of the profile is <span class="math">2<em>r</em>sin<em>α</em> / 2</span> (Figure [f:x1AndInt]b). During this first interval, the size of <span class="math"><em>α</em></span> limits the width of the profile. When the animal reaches <span class="math"><em>x</em><sub>1</sub></span> = <span class="math"><em>θ</em> / 2 + <em>π</em> / 2 − <em>α</em> / 2</span> (Figure [f:x1AndInt]c), the size of the profile is <span class="math"><em>r</em>sin(<em>α</em> / 2) + <em>r</em>cos(<em>x</em><sub>1</sub> − <em>θ</em> / 2)</span> and the size of <span class="math"><em>θ</em></span> and <span class="math"><em>α</em></span> both limit the width of the profile (Figure  [f:x1AndInt]c). Finally, at <span class="math"><em>x</em><sub>1</sub> = 5<em>π</em> / 2 − <em>θ</em> / 2 − <em>α</em> / 2</span> until <span class="math"><em>x</em><sub>1</sub> = 3<em>π</em> / 2</span>, the width of the profile is again <span class="math">2<em>r</em>sin<em>α</em> / 2</span> (Figure  [f:x1AndInt]d) and the size of <span class="math"><em>α</em></span> again limits the width of the profile.</p>
<p>[t] <embed src="imgs/fourIntegrals.pdf"> An overview of the derivation of the average profile <span class="math"><em>p̄</em></span> for the gREM submodel SE2, where (a) shows the location of the profile <span class="math"><em>p</em></span> (the line an animal must pass through in order to be captured) in red and the focal angle, <span class="math"><em>x</em><sub>1</sub></span>, for an animal (filled circle), its signal (unfilled sector), and direction of movement (shown as an arrow). The detection zone of the sensor is shown as a filled grey sector with a detection distance of <span class="math"><em>r</em></span>. The vertical black line within the circle shows the direction the sensor is facing. The derivation of <span class="math"><em>p</em></span> changes as the animal approaches the sensor from different directions (shown in b-d), where (b) is the derivation of <span class="math"><em>p</em></span> when <span class="math"><em>x</em><sub>1</sub></span> is in the interval <span class="math">$\lbrack\frac{\pi}{2}, \frac{\pi}{2} + \frac{\theta}{2} - \frac{\alpha}{2}\rbrack$</span>, (c) <span class="math"><em>p</em></span> when <span class="math"><em>x</em><sub>1</sub></span> is in the interval <span class="math">$\lbrack\frac{\pi}{2} + \frac{\theta}{2} - \frac{\alpha}{2}, \frac{5 \pi}{2} - \frac{\theta}{2} - \frac{\alpha}{2} \rbrack$</span> and (d) <span class="math"><em>p</em></span> when <span class="math"><em>x</em><sub>1</sub></span> is in the interval <span class="math">$\lbrack\frac{5 \pi}{2} - \frac{\theta}{2} - \frac{\alpha}{2}, \frac{3 \pi}{2}\rbrack$</span>, where <span class="math"><em>θ</em></span>, sensor detection width; <span class="math"><em>α</em></span>, animal signal width. The resultant equation for <span class="math"><em>p</em></span> is shown beneath b-d. The average profile <span class="math"><em>p̄</em></span> is the size of the profile averaged across all approach angles. [f:x1AndInt]</p>
<p>The profile width <span class="math"><em>p</em></span> for <span class="math"><em>π</em></span> radians of rotation (from directly towards the sensor to directly behind the sensor) is completely characterised by the three intervals (Figure [f:x1AndInt]b–d). Average profile width <span class="math"><em>p̄</em></span> is calculated by integrating these profiles over their appropriate intervals of <span class="math"><em>x</em><sub>1</sub></span> and dividing by <span class="math"><em>π</em></span> which gives</p>
<p><br /><span class="math">$\begin{aligned*}
    \bar{p} &amp;=\frac{1}{\pi} \left(\int\limits_{\frac{\pi}{2}}^{\frac{\pi}{2} + \frac{\theta}{2} - \frac{\alpha}{2}}2 r \sin{\frac{\alpha}{2} }\;\mathrm{d}x_1+\int\limits_{\frac{\pi}{2} + \frac{\theta}{2} - \frac{\alpha}{2}}^{\frac{5 \pi}{2} - \frac{\theta}{2} - \frac{\alpha}{2}}r \sin{\frac{\alpha}{2} } + r \cos{\left (x_1 - \frac{\theta}{2} \right )}\;\mathrm{d}x_1+\int\limits_{\frac{5 \pi}{2} - \frac{\theta}{2} - \frac{\alpha}{2}}^{\frac{3 \pi}{2}}2 r \sin{\frac{\alpha}{2} }\;\mathrm{d}x_1\right) \label{e:SE2int}  \\
     &amp;= \frac{r}{\pi} \left(\theta \sin{\frac{\alpha}{2} } - \cos{\frac{\alpha}{2} } + \cos{\left (\frac{\alpha}{2} + \theta \right )}\right) \label{e:SE2result}\end{aligned*}$</span><br /></p>
<p>We then use this expression to calculate density</p>
<p><br /><span class="math">$\label{e:gas}
D = z/vt\bar{p}.$</span><br /></p>
<p>Rather than having one equation that describes <span class="math"><em>p̄</em></span> globally, the gREM must be split into submodels due to discontinuous changes in <span class="math"><em>p</em></span> as <span class="math"><em>α</em></span> and <span class="math"><em>β</em></span> change. These discontinuities can occur for a number of reasons such as a profile switching between being limited by <span class="math"><em>α</em></span> and <span class="math"><em>θ</em></span>, the difference between very small profiles and profiles of size zero and the fact that the width of a sector stops increasing once the central angle reaches <span class="math"><em>π</em></span> radians (i.e., a semi circle is just as wide as a full circle.)</p>
<p>As an example, if <span class="math"><em>α</em></span> is small, there is an interval between Figure [f:x1AndInt]c and [f:x1AndInt]d where the ‘blind spot’ would prevent animals being detected giving <span class="math"><em>p</em> = 0</span>. This would require an extra integral in our equation as simply putting our small value of <span class="math"><em>α</em></span> into [e:SE2int] would not give us this integral of <span class="math"><em>p</em> = 0</span>.</p>
<p>gREM submodel specifications were done by hand, and the integration was done using SymPy <span class="citation"></span> in Python (Appendix S3). The gREM submodels were checked by confirming that: (1) submodels adjacent in parameter space were equal at the boundary between them; (2) submodels that border <span class="math"><em>α</em> = 0</span> had <span class="math"><em>p</em> = 0</span> when <span class="math"><em>α</em> = 0</span>; (3) average profile widths <span class="math"><em>p̄</em></span> were between 0 and <span class="math">2<em>r</em></span> and; (4) each integral, divided by the range of angles that it was integrated over, was between 0 and <span class="math">2<em>r</em></span>. The scripts for these tests are included in Appendix S3 and the R <span class="citation"></span> implementation of the gREM is given in Appendix S4.</p>
<h2 id="simulation-model">Simulation Model</h2>
<p>We tested the accuracy and precision of the gREM by developing a spatially explicit simulation of the interaction of sensors and animals using different combinations of sensor detection widths, animal signal widths, number of captures, and models of animal movement. 100 simulations were run where each consisted of a 7.5 by 7.5 square with periodic boundaries. A stationary sensor of radius <span class="math"><em>r</em></span> was set up in the exact centre of each simulation, covering seven sensor detection widths <span class="math"><em>θ</em></span>, between 0 and <span class="math">2<em>π</em></span> (<span class="math">2 / 9<em>π</em></span>, <span class="math">4 / 9<em>π</em></span>, <span class="math">6 / 9<em>π</em></span>, <span class="math">8 / 9<em>π</em></span>, <span class="math">10 / 9<em>π</em></span>, <span class="math">14 / 9<em>π</em></span>, and <span class="math">2<em>π</em></span>). Each sensor was set to record continously and to capture animal signals instaneously from emission. Each simulation was populated with a density of 70, calculated from the equation in <span class="citation"></span> as the expected density of mammals of weighing 1. This density therefore represents a reasonable estimate of density of individuals, given that the smallest mammal is around 2 <span class="citation"></span>. A total of 3937 individuals per simulation were created which were placed randomly at the start of the simulation. Individuals were assigned 11 signal widths <span class="math"><em>α</em></span> between 0 and <span class="math"><em>π</em></span> (<span class="math">1 / 11<em>π</em></span>, <span class="math">2 / 11<em>π</em></span>, <span class="math">3 / 11<em>π</em></span>, <span class="math">4 / 11<em>π</em></span>, <span class="math">5 / 11<em>π</em></span>, <span class="math">6 / 11<em>π</em></span>, <span class="math">7 / 11<em>π</em></span>, <span class="math">8 / 11<em>π</em></span>, <span class="math">9 / 11<em>π</em></span>, <span class="math">10 / 11<em>π</em></span>, <span class="math"><em>π</em></span>).</p>
<p>Each simulation lasted for <span class="math"><em>N</em></span> steps (14400) of duration <span class="math"><em>T</em></span> (15 minutes) giving a total duration of 150 days. The individuals moved within each step with a distance <span class="math"><em>d</em></span>, with an average speed, <span class="math"><em>v</em></span>. <span class="math"><em>d</em></span>, was sampled from a normal distribution with mean distance, <span class="math"><em>μ</em><sub><em>d</em></sub> = <em>v</em><em>T</em></span>, and standard deviation <span class="math"><em>σ</em><sub><em>d</em></sub> = <em>v</em><em>T</em> / 10</span>. An average speed, <span class="math"><em>v</em> = </span> 40, was chosen as this is the largest day range of terrestrial animals <span class="citation"></span>, and represents the upper limit of realistic speeds. At the end step, individuals were allowed to either remain stationary for a time step (with a given probability, <span class="math"><em>S</em></span>), or change direction (in a uniform distribution with a maximum angle, <span class="math"><em>A</em></span>) between 0 and <span class="math"><em>π</em></span>. This resulted in seven different movement models where: (1) simple movement, where <span class="math"><em>S</em></span> and <span class="math"><em>A</em></span> = 0; (2) stop-start movement, where (i) <span class="math"><em>S</em></span> = 0.25, <span class="math"><em>A</em></span> = 0, (ii) <span class="math"><em>S</em></span> = 0.5, <span class="math"><em>A</em></span> = 0, (iii) <span class="math"><em>S</em></span> = 0.75, <span class="math"><em>A</em></span> = 0; (3) random walk movement, where (i) <span class="math"><em>S</em></span> = 0, <span class="math"><em>A</em></span> = <span class="math"><em>π</em> / 3</span>, (ii) <span class="math"><em>S</em></span> = 0, <span class="math"><em>A</em></span> = <span class="math">2<em>π</em> / 3</span>, iii) <span class="math"><em>S</em></span> = 0, <span class="math"><em>A</em></span> = <span class="math"><em>π</em></span>. Individuals were counted as they moved in and out of the detection zone of the sensor per simulation.</p>
<p>We calculated the estimated animal density from the gREM by asumming the number of captures per simulation and inputting these values into the correct gREM submodel. gREM accuracy was determined by comparing the density in the simulation with the estimated density. High accuracy is indicated by the mean difference between the estimated and actual values not being significantly different from zero (Wilcoxon signed-rank test). gREM precision was determined by the standard deviation of estimated densities. We used this method to compare the accuracy and precision of all the gREM submodels. As these submodels are derived for different combinations of <span class="math"><em>α</em></span> and <span class="math"><em>θ</em></span>, the accuracy and precision of the submodels was used to determine the impact of different values of <span class="math"><em>α</em></span> and <span class="math"><em>θ</em></span>.</p>
<p>The influence of the number of captures and animal movement models on accuracy and precision was investigated using four different gREM submodels representative of the range <span class="math"><em>α</em></span> and <span class="math"><em>θ</em></span> values (submodels NW1, SW1, NE1, and SE3, Figure [f:equalRegions]). Using these four submodels, we calculated how long the simulation needed to run to generate a range of different capture numbers (from 10 to 100 captures in 10 unit intervals), and estimated animal density. These estimated densities were compared to the real density to assess the impact on the accuracy and precision of the gREM. We calculated the coefficient of variation in order the compare the precision between capture numbers. The gREM also assumes that individuals move continuously with straight-line movement (simple movement model) and we therefore assessed the impact of breaking the gREM assumptions. We used the four submodels to compare the accuracy and precision of a simple movement model, stop-start movement models (using different amounts of time spent stationary), and random walk movement models.</p>
<h1 id="results">Results</h1>
<h2 id="analytical-model-1">Analytical model</h2>
<p>The equation for <span class="math"><em>p̄</em></span> has been newly derived for each submodel in the gREM, except for the gas model and REM which have been calculated previously. However, many models, although derived separately, have the same expression for <span class="math"><em>p̄</em></span>. Figure [f:equalModelResults] shows the expression for <span class="math"><em>p̄</em></span> in each case. The general equation for density, using the correct expression for <span class="math"><em>p̄</em></span> is then substituted into [e:gas]. Although more thorough checks are performed in Appendix S3, it can be seen that all adjacent expressions in Figure [f:equalModelResults] are equal when expressions for the boundaries between them are substituted in.</p>
<p><embed src="imgs/equalModelResults.pdf"> Expressions for the average profile width, <span class="math"><em>p̄</em></span>, given a range of sensor and signal widths. Despite independent derivation within each block, many models result in the same expression. These are collected together and presented as one block of colour. Expressions on the edge of the plot are for submodels with <span class="math"><em>α</em>, <em>θ</em> = 2<em>π</em></span>. [f:equalModelResults]</p>
<h2 id="simulation-model-1">Simulation model</h2>
<h3 id="grem-submodels">gREM submodels</h3>
<p>All gREM submodels showed a high accuracy, i.e., the mean difference between the estimated and actual values was not significantly different from zero across all models, corrected for multiple tests (all gREM sub models Wilcoxon signed-rank test, p &gt;0.002) (Figure [f:ModelBias]). However, the precision of the submodels do vary, where the gas model is the most precise and the SW7 sub model the least precise, having the smallest and the largest interquartile range, respectively (Figure [f:ModelBias]). The standard deviation of the error between the estimated and true densities is strongly related to both the sensor and signal widths (Figure [f:StandardDevaition]), such that larger widths have lower standard deviations (greater precision).</p>
<p>[t] <embed src="imgs/AverageModelBias.pdf"> Simulation model results of the accuracy and precision for gREM submodels. The percentage error between estimated and true density for each gREM sub model is shown within each box plot, where the black line represents the median percentage error across all simulations, boxes represent the middle 50% of the data, whiskers represent variability outside the upper and lower quartiles with outliers plotted as individual points. Box colours correspond to the expressions for average profile width <span class="math"><em>p̄</em></span> given in Figure 4. [f:ModelBias]</p>
<p>[t] <embed src="imgs/ResultStandardDeviation.pdf"> Simulation model results of the gREM precision given a range of sensor and signal widths, shown by the standard deviation of the error between the estimated and true densities. Standard deviations are shown from deep red to pink, representing high to low values between <span class="math">0. 483 × 10<sup> − 6</sup></span> to <span class="math">3. 74 × 10<sup> − 6</sup></span>. [f:StandardDevaition]</p>
<h3 id="number-of-captures">Number of captures</h3>
<p>Within the four gREM submodels tested (NW1, SW1, SE3, NE1), the accuracy was not affected by the number of captures, where the mean difference between the estimated and actual values was not significantly different from zero across all capture rates, corrected for multiple tests (all gREM sub models Wilcoxon signed-rank test, p &gt;0.008) (Figure [f:Captures]). However, the precision was dependent on the number of captures across all four of the gREM submodels, where precision increases as number of captures increases (Figure [f:Captures]). For all gREM submodels, the the coefficient of variation falls to 10% at 100 captures.</p>
<p>[t] <embed src="imgs/ResultsNoCaptures.pdf"> Simulation model results of the accuracy and precision of four gREM submodels (NW1, SW1, SE3 and NE1) given different numbers of captures. The percentage error between estimated and true density within each gREM sub model for capture rate is shown within each box plot, where the black line represents the median percentage error across all simulations, boxes represent the middle 50% of the data, whiskers represent variability outside the upper and lower quartiles with outliers plotted as individual points. Sensor and signal widths vary between submodels. The numbers beneath each plot represent the coefficient of variation. The colour of each box plot corresponds to the expressions for average profile width <span class="math"><em>p̄</em></span> given in Figure 4. [f:Captures]</p>
<h3 id="movement-models">Movement models</h3>
<p>Within the four gREM submodels tested (NW1, SW1, SE3, NE1), neither the accuracy or precision was affected by the amount of time spent stationary. The mean difference between the estimated and actual values was not significantly different from zero for each category of stationary time (0, 0.25, 0.5 and 0.75), corrected for multiple tests (all gREM sub models Wilcoxon signed-rank test, p &gt;0.12) (Figure [f:Perch]). Altering the maximum change in direction in each step (0, pi/3, 2pi/3, and pi) did not affect the accuracy or precision of the four gREM submodels tested (all gREM sub models Wilcoxon signed-rank test, p &gt;0.05) (Figure [f:Tort]).</p>
<p>[t]</p>
<p>[t]60mm <embed src="imgs/ResultsPerch(new).pdf"> [f:Perch]</p>
<p>[t]60mm <embed src="imgs/ResultsTort(new).pdf"> [f:Tort]</p>
<p>[f:BreakAssump] Simulation model results of the accuracy and precision of four gREM submodels (NW1, SW1, SE3 and NE1) given different movement models where (a) amount of time spent stationary (stop-start movement) and (b) maximum change in direction at each step (correlated random walk model). The percentage error between estimated and true density within each gREM sub model for the different movement models is shown within each box plot, where the black line represents the median percentage error across all simulations, boxes represent the middle 50% of the data, whiskers represent variability outside the upper and lower quartiles with outliers plotted as individual points. The simple model is represented where time and maximum change in direction equals 0. The colour of each box plot corresponds to the expressions for average profile width <span class="math"><em>p̄</em></span> given in Figure 4.</p>
<h1 id="discussion">Discussion</h1>
<p>We have developed the gREM such that it can be used to estimate density from acoustic sensors and camera traps. This has entailed a generalisation of the gas model and the REM in <span class="citation"></span> to be applicable to any combination of sensor width and signal directionality. We have used simulations to show, as a proof of principle, that these models are accurate and precise. The precision of the gREM was found to be dependent on the width of the sensor and the signal, and the number of captures.</p>
<h2 id="analytical-model-2">Analytical model</h2>
<p>The gREM was derived for different combinations of <span class="math"><em>α</em></span> and <span class="math"><em>θ</em></span> resulting in 25 different submodels, the expression for <span class="math"><em>p̄</em></span> are equal for many of these submodels resulting in eight different equations including the previously derived gas model and REM. These submodels were tested for consistency with adjacent expressions being equal at their boundaries. These new submodels will allow researchers to evaluate the absolute density of animals that have previously been difficult to study, such as bats <span class="citation"></span>, with non-invasive methods such as remote sensors. The gREM also allows the data from acoustic detectors to be used where an animal has a directional calls, this could be used for a range of animals including songbirds <span class="citation"></span>, dolphins <span class="citation"></span>, as well as bats <span class="citation"></span>.</p>
<p>There are a number of possible extensions to the gREM which could be developed in the future. The original gas model was formulated for the case where both subjects, either animal and detector, or animal and animal, are moving <span class="citation"></span>. Indeed any of the models with animals that are equally detectable in all directions (<span class="math"><em>α</em> = 2<em>π</em></span>) can be trivially expanded for moving by substituting the sum of the average animal velocity and the sensor velocity for <span class="math"><em>v</em></span> as used here. However, when the animal has a directional call, as seen in both terrestrial and aquatic environments <span class="citation"></span>, the extension becomes less simple. The approach would be to calculate again the mean profile width. However, for each angle of approach, one would have to average the profile width for an animal facing in any direction (i.e. not necessarily moving towards the sensor) weighted by the relative velocity of that direction. There are a number of situations where a moving detector and animal could occur, e.g. an acoustic detector towed from a boat when studying porpoises <span class="citation"></span> or surveying bats from a moving car <span class="citation"></span>.</p>
<p>Interesting but unstudied problems impacting the gREM are firstly, edge effects caused by sensor trigger delays (the delay between sensing an animal and attempting to record the encounter) <span class="citation"></span>, and secondly, sensors which repeatedly turn on an off during sampling <span class="citation"></span>. The second problem is particualrly relevant to acoustic detectors which record ultrasound by time expansion. Here ultrasound is recorded for a set time period and then slowed down and played back, rendering the sensor ’deaf’ periodically during sampling. Both of these problems may cause biases in the gREM, as animals can move through the detection zone without being detected. As the gREm assumes constant surveillance, the error created by switching the sensor on and off quickly will become more important if the sensor is only on for short periods of time. For example, if it takes longer for the recording device to be switched on than the length of some animal calls then there could be a systematic underestimation of density. We recommend that the gREM is applied to constantly sampled data, and the impacts of breaking these assumptions on the gREM should be further explored.</p>
<h2 id="accuracy-precision-and-recommodations-for-best-practice">Accuracy, Precision and Recommodations for Best Practice</h2>
<p>Based on our simulations we believe that the gREM has the potential to produce accurate estimates for many different species, using either camera traps or acoustic detectors. However the precision of the gREM differed between submodels. For example, when the sensor and signal width were small, the precision of the model was reduced. Therefore when choosing a sensor for use in a gREM study, the sensor detection width should be maximised. If the study species has a narrow signal directionality, other aspects of the study protocol, such as length of the survey, should be used to compensate.</p>
<p>The precision of the gREM is greatly affected by the number of captures. The coefficient of variation falls dramatically between 10 and 60 captures and then after this continues to slowly reduce. At 100 captures the submodels reach 10% coefficient of variation, considered to a very good level of precision <span class="citation"></span>. Many current studies do not reach this level of precision, with most studies reporting coefficient of variations greater than the 10% level <span class="citation"></span>. The length of surveys in the field will need to be adjusted so that enough data can be collected to reach this precision level. Populations of fast moving animals or populations with high densities will require less survey effort than those species that are slow moving or have populations with low densities.</p>
<p>The gREM was both accurate and precise for all the movement models we tested (stop-start movement and correlated random walks). However these movement models are still simple representations of true animal movement which are dependent on multiple factors such as behavioural state and existence of home ranges <span class="citation"></span>. The accuracy of the gREM may be affected by the interaction between the movement model and the size of the detection radius. We have studied a relatively long step length compared to the size of the detection radius, and therefore the chance of catching the same animal multiple times within a short space of time was reduced and there is little effect on the precision of the model (Figure [f:Tort]). However if the ratio of step length to detection radius was smaller then this may decrease the precision of the model, however this should not decrease its accuracy.</p>
<h2 id="limitations">Limitations</h2>
<p>Although we have used simulations to validate the gREM submodels, much more robust testing is needed. Although difficult, proper field test validation would be required before the models could be fully trusted. The REM <span class="citation"></span> has already been field tested, and both <span class="citation"></span> and <span class="citation"></span> both found that the REM was an effective manner of estimating animal densities <span class="citation"></span>. In some taxa gold standard methods of estimating animal density exist, such as capture mark recapture <span class="citation"></span>. Where these gold standard exist or true numbers are known, a simultaneous gREM study could be completed to test the accuracy under field conditions, similar to the tests in <span class="citation"></span>. An easier way to continue to evaluate the models is to run more extensive simulations which break the assumptions of the analytical models. The main element that cannot be analytically treated is the complex movement of real animals. Therefore testing these methods against true animal traces, or more complex movement models would be required.</p>
<p>Within the simulation we have assumed an equal density across the entire world, however in a field environment the situation would be much more complex, with additional variation coming from local changes in density between sensor sites. We allowed the sensor to be stationary and continuously detecting, negating the triggering, and non-continuous recording issues that could exist with some sensors. In the simulation, the distance travelled of animal was assumed to be <span class="math">$\SI{40}{\kilo\meter \per \day}$</span>, the largest day range of terrestrial animals <span class="citation"></span>. Other speed values should not alter the accuracy of the gREM, however, precision would be affected, all else being equal, since slower speeds produce fewer records. We also assume perfect knowledge of the average speed of an animal and size of the detection zone. All of which may lead to possible bias or a decrease in precision.</p>
<h2 id="implications-for-ecology-and-conservation">Implications for ecology and conservation</h2>
<p>The gREM can estimate densities of a number of taxa where no, or few, accurate methods currently exist to measure absolute animal density and trends in absolute abundances <span class="citation"></span>. Many of these species are critically endangered and monitoring their populations is of conservation interest. For example, current methods of density estimation for the threatened Francisana dolphin (<em>Pontoporia blainvillei</em>) may result in underestimation of their numbers <span class="citation"></span>. Our method may also be important for understanding zoonotic diseases, for example estimating population sizes of echolocating bats, which are important reservoir of infectious disease that affect humans, livestock and wildlife <span class="citation"></span>. In addition, the gREM will make it possible to measure the density of animals which may be useful in quantifying ecosystem services, such as studying the levels of songbirds which are known to have a positive influence on pest control in coffee production <span class="citation"></span>. The gREM is suitable for any species that would be consistently recorded within range of a detector, such as echolocating bats <span class="citation"></span>, songbirds <span class="citation"></span>, whales <span class="citation"></span> or forest primates <span class="citation"></span>. With increasing technological capabilities, this list of species is likely to increase dramatically. Finally, the passive sensor methods that the gREM use are noninvasive and do not require individual marking <span class="citation"></span> or naturally identifying marks (as required for mark-recapture models). This makes them suitable for large, continuous monitoring projects with limited human resources <span class="citation"></span>. It also makes them suitable for species that are under pressure, species that cannot naturally be individually recognised or species that are difficult or dangerous to catch <span class="citation"></span>.</p>
<h1 id="acknowledgments">Acknowledgments</h1>
<p>We thank Hilde Wilkinson-Herbot, Chris Carbone, Francois Balloux, Andrew Cunningham, and Steve Hailes for comments on previous versions of the manuscript. This study was funded through CoMPLEX PhD studenships at University College London suported by BBSRC and EPSRC (EAM and TCDL) and The Darwin Initiative (Awards 15003, 161333, EIDPR075 to KEJ), the Leverhulme Trust (Philip Leverhulme Prize for KEJ).</p>
